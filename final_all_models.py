# -*- coding: utf-8 -*-
"""final all models

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o1RUij2601ygAPvIDbzmn-Z974E9YZl_
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
try:
    df = pd.read_csv('labeled_text.csv')
except FileNotFoundError:
    print("Error: labeled_text.csv not found. Please ensure the file is in the correct directory.")
    exit()

# Separate features (cleaned_text) and target (sentiment)
X = df['cleaned_text']
y = df['sentimen']

# Split data into training and testing sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000) # You can adjust max_features

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the test data
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# --- Model 1: Random Forest ---
print("--- Random Forest Classifier ---")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_tfidf, y_train)
y_pred_rf = rf_model.predict(X_test_tfidf)

# Confusion Matrix - Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Classification Report - Random Forest
print("=== Classification Report - Random Forest ===")
print(classification_report(y_test, y_pred_rf, target_names=rf_model.classes_))
print("\n")

# --- Model 2: Naive Bayes (MultinomialNB) ---
print("--- Naive Bayes Classifier (MultinomialNB) ---")
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
y_pred_nb = nb_model.predict(X_test_tfidf)

# Confusion Matrix - Naive Bayes
cm_nb = confusion_matrix(y_test, y_pred_nb)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)
plt.title('Confusion Matrix - Naive Bayes')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Classification Report - Naive Bayes
print("=== Classification Report - Naive Bayes ===")
print(classification_report(y_test, y_pred_nb, target_names=nb_model.classes_))
print("\n")

# --- Model 3: Support Vector Machine (SVM) ---
print("--- Support Vector Machine (SVM) Classifier ---")
svm_model = SVC(kernel='linear', random_state=42) # 'linear' kernel is a good starting point for text data
svm_model.fit(X_train_tfidf, y_train)
y_pred_svm = svm_model.predict(X_test_tfidf)

# Confusion Matrix - SVM
cm_svm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)
plt.title('Confusion Matrix - SVM')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Classification Report - SVM
print("=== Classification Report - SVM ===")
print(classification_report(y_test, y_pred_svm, target_names=svm_model.classes_))
print("\n")